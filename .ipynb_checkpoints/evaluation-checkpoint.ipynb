{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36dfbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fpdf2 in /opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages (2.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages (from fpdf2) (0.7.1)\n",
      "Requirement already satisfied: Pillow!=9.2.*,>=8.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages (from fpdf2) (11.1.0)\n",
      "Requirement already satisfied: fonttools>=4.34.0 in /opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages (from fpdf2) (4.55.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_fsdp_enabled' from 'transformers.integrations' (/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/integrations/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfitz\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/sentence_transformers/__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     AutoConfig,\n\u001b[32m     18\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     19\u001b[39m     AutoTokenizer,\n\u001b[32m     20\u001b[39m     PretrainedConfig,\n\u001b[32m     21\u001b[39m     PreTrainedModel,\n\u001b[32m     22\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/utils/import_utils.py:2154\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2152\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m   2153\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2154\u001b[39m         module = \u001b[38;5;28mself\u001b[39m._get_module(\u001b[38;5;28mself\u001b[39m._class_to_module[name])\n\u001b[32m   2155\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2156\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/utils/import_utils.py:2184\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   2183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/utils/import_utils.py:2182\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   2181\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2182\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap._gcd_import(name[level:], package, level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/modeling_utils.py:51\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_fsdp_enabled' from 'transformers.integrations' (/opt/homebrew/Caskroom/miniconda/base/envs/aiml/lib/python3.12/site-packages/transformers/integrations/__init__.py)"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# SMART RESUME ANALYZER - EVALUATION NOTEBOOK\n",
    "# =======================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "%pip install fpdf2\n",
    "from fpdf import FPDF\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import tempfile\n",
    "\n",
    "# ---- import analyzer pieces ----\n",
    "import fitz\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- YOUR ANALYZER FUNCTIONS -----------------\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\".join([page.get_text() for page in doc])\n",
    "\n",
    "SECTION_PATTERNS = {\n",
    "    \"Education\": r\"(?i)\\b(education|academic background)\\b\",\n",
    "    \"Experience\": r\"(?i)\\b(work experience|professional experience|employment history|experience)\\b\",\n",
    "    \"Projects\": r\"(?i)\\b(projects|personal projects)\\b\",\n",
    "    \"Skills\": r\"(?i)\\b(skills|technical skills|key skills)\\b\",\n",
    "    \"Certifications\": r\"(?i)\\b(certifications|licenses)\\b\",\n",
    "    \"Summary\": r\"(?i)\\b(career objective|summary|professional summary|objective)\\b\",\n",
    "    \"Contact\": r\"(?i)\\b(phone|email|linkedin|github)\\b\",\n",
    "    \"Achievements\": r\"(?i)\\b(achievements|awards|honors)\\b\",\n",
    "    \"Languages\": r\"(?i)\\b(languages spoken|languages)\\b\",\n",
    "    \"Tools\": r\"(?i)\\b(technologies|tools|software)\\b\"\n",
    "}\n",
    "def analyze_sections(text):\n",
    "    section_stats = {}\n",
    "    for section, pattern in SECTION_PATTERNS.items():\n",
    "        match = re.search(pattern, text)\n",
    "        present = bool(match)\n",
    "        bullet_count = 0\n",
    "        if present:\n",
    "            section_text = text[match.start():match.start() + 1000]\n",
    "            bullet_count = len(re.findall(r\"[\\n•\\-‣▪▶●][ \\t]*\", section_text))\n",
    "        section_stats[section] = {\"present\": present, \"bullet_count\": bullet_count}\n",
    "    return section_stats\n",
    "\n",
    "def calculate_ats_score(text):\n",
    "    if not text:\n",
    "        return 0\n",
    "    lower = text.lower()\n",
    "    score = 0\n",
    "    total = 12\n",
    "    sections = analyze_sections(text)\n",
    "    if sections[\"Experience\"][\"present\"]: score += 2\n",
    "    if sections[\"Education\"][\"present\"]: score += 2\n",
    "    if sections[\"Skills\"][\"present\"]: score += 2\n",
    "    for sec in [\"Projects\", \"Certifications\", \"Achievements\"]:\n",
    "        if sections[sec][\"present\"]:\n",
    "            score += 1\n",
    "    if re.search(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", lower): score += 1\n",
    "    if re.search(r'(\\+?\\d[\\d\\-\\s]{8,}\\d)', lower): score += 1\n",
    "    if re.search(r\"\\b\\d{4}\\b\", lower): score += 1\n",
    "    if len(text.split()) > 250: score += 1\n",
    "    total_bullets = sum(info[\"bullet_count\"] for info in sections.values())\n",
    "    if total_bullets >= 5: score += 1\n",
    "    return min(int((score/total)*100), 100)\n",
    "\n",
    "# --- Load your skills dataset ---\n",
    "skills_df = pd.read_csv(\"skills_dataset_top50000.csv\")\n",
    "skills_list = sorted([s.strip().lower() for s in skills_df[\"Skill\"].dropna()], key=len, reverse=True)\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    found_skills = set()\n",
    "    text_lower = text.lower()\n",
    "    for skill in skills_list:\n",
    "        if re.search(rf\"\\b{re.escape(skill)}\\b\", text_lower):\n",
    "            found_skills.add(skill)\n",
    "    return found_skills\n",
    "\n",
    "# --- JD Ranking using your actual logic ---\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def rank_resumes(jd_text, resume_paths):\n",
    "    jd_skills = extract_skills_from_text(jd_text)\n",
    "    jd_skills = [s.lower() for s in jd_skills]\n",
    "    jd_skill_embeddings = embedding_model.encode(jd_skills, convert_to_tensor=True) if jd_skills else None\n",
    "    jd_text_embedding = embedding_model.encode(jd_text, convert_to_tensor=True)\n",
    "\n",
    "    ranked_list = []\n",
    "    for path in resume_paths:\n",
    "        text = extract_text_from_pdf(path)\n",
    "        resume_skills = extract_skills_from_text(text)\n",
    "        resume_skills = [s.lower() for s in resume_skills]\n",
    "\n",
    "        # skill match\n",
    "        skill_match = 0.0\n",
    "        if resume_skills and jd_skill_embeddings is not None:\n",
    "            resume_skill_embeddings = embedding_model.encode(resume_skills, convert_to_tensor=True)\n",
    "            cosine_scores = util.cos_sim(resume_skill_embeddings, jd_skill_embeddings)\n",
    "            best_for_each_jd = cosine_scores.max(dim=0).values\n",
    "            skill_match = float(best_for_each_jd.mean().item())\n",
    "\n",
    "        # semantic similarity\n",
    "        semantic_score = float(util.cos_sim(\n",
    "            embedding_model.encode(text, convert_to_tensor=True),\n",
    "            jd_text_embedding\n",
    "        ).item())\n",
    "\n",
    "        skill_match = max(0.0, min(1.0, skill_match))\n",
    "        semantic_score = max(0.0, min(1.0, semantic_score))\n",
    "        ats_score = max(0.0, min(1.0, calculate_ats_score(text) / 100))\n",
    "\n",
    "        final_score = 0.45*skill_match + 0.35*semantic_score + 0.2*ats_score\n",
    "        ranked_list.append({\n",
    "            \"filename\": os.path.basename(path),\n",
    "            \"skill_match\": round(skill_match*100,1),\n",
    "            \"semantic_score\": round(semantic_score*100,1),\n",
    "            \"ats_score\": round(ats_score*100,1),\n",
    "            \"final_score\": round(final_score*100,1)\n",
    "        })\n",
    "\n",
    "    return sorted(ranked_list, key=lambda x: x['final_score'], reverse=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"test_resumes\", exist_ok=True)\n",
    "NUM_RESUMES = 20\n",
    "\n",
    "skills_pool = {\n",
    "    \"Software Engineer\": [\"Python\", \"Flask\", \"Django\", \"SQL\", \"Git\", \"REST API\", \"Docker\", \"Linux\"],\n",
    "    \"Data Scientist\": [\"Python\", \"Pandas\", \"NumPy\", \"Machine Learning\", \"TensorFlow\", \"Scikit-learn\", \"SQL\", \"Data Visualization\"],\n",
    "    \"Web Developer\": [\"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Node.js\", \"MongoDB\", \"Git\", \"Bootstrap\"],\n",
    "    \"Mobile Developer\": [\"Java\", \"Kotlin\", \"Android\", \"Firebase\", \"Git\", \"REST API\"],\n",
    "    \"Cloud Engineer\": [\"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Linux\", \"Terraform\", \"CI/CD\"],\n",
    "    \"Cybersecurity Analyst\": [\"Network Security\", \"Penetration Testing\", \"SIEM\", \"Python\", \"Linux\", \"Incident Response\"],\n",
    "    \"Product Manager\": [\"Agile\", \"Scrum\", \"JIRA\", \"Roadmapping\", \"Market Research\", \"Stakeholder Management\"],\n",
    "    \"AI Engineer\": [\"Deep Learning\", \"PyTorch\", \"Computer Vision\", \"NLP\", \"Transformers\", \"Python\", \"MLOps\"],\n",
    "}\n",
    "roles = list(skills_pool.keys())\n",
    "universities = [\"IIT Bombay\", \"IIT Delhi\", \"MIT Pune\", \"VIT Vellore\", \"BITS Pilani\", \"Stanford University\", \"Harvard University\"]\n",
    "companies = [\"Google\", \"Microsoft\", \"Amazon\", \"Adobe\", \"Tesla\", \"Flipkart\", \"TCS\", \"Infosys\", \"IBM\", \"Meta\"]\n",
    "\n",
    "def generate_resume(role):\n",
    "    name = random.choice([\"John\", \"Jane\", \"Rahul\", \"Aisha\", \"Mark\", \"Priya\", \"Siddharth\", \"Emily\", \"Karan\", \"Meera\"]) \\\n",
    "           + \" \" + random.choice([\"Doe\", \"Smith\", \"Kumar\", \"Khan\", \"Lee\", \"Patel\", \"Gupta\", \"Sharma\"])\n",
    "    uni = random.choice(universities)\n",
    "    company = random.choice(companies)\n",
    "    skills = random.sample(skills_pool[role], k=min(len(skills_pool[role]), random.randint(4,6)))\n",
    "    degree = random.choice([\"B.Tech\", \"B.E.\", \"M.Tech\", \"M.Sc.\", \"MBA\"])\n",
    "    exp_years = random.randint(1,6)\n",
    "    resume_text = f\"\"\"\n",
    "{name}\n",
    "Email: {name.lower().replace(' ','.')}@example.com | Phone: +91-9876543210 | LinkedIn: linkedin.com/in/{name.lower().replace(' ','')}\n",
    "Education:\n",
    "- {degree} in Computer Science from {uni}, Graduation Year {2017+exp_years}\n",
    "\n",
    "Experience:\n",
    "- {role} at {company} ({exp_years} years)\n",
    "  Worked on multiple projects involving {', '.join(skills)}.\n",
    "  Designed and implemented solutions improving performance and scalability.\n",
    "\n",
    "Projects:\n",
    "- {role} Portfolio Project — Built using {', '.join(skills[:3])}\n",
    "- Data analysis and visualization on large datasets to derive actionable insights.\n",
    "\n",
    "Skills:\n",
    "{', '.join(skills)}\n",
    "\n",
    "Certifications:\n",
    "- {role} Certification from Coursera\n",
    "- Cloud Fundamentals (AWS)\n",
    "\n",
    "Achievements:\n",
    "- Awarded best {role} intern at {company}\n",
    "    \"\"\"\n",
    "    return resume_text.strip(), skills\n",
    "\n",
    "pdf_paths = []\n",
    "ground_truth_skills = []\n",
    "for i in range(NUM_RESUMES):\n",
    "    role = random.choice(roles)\n",
    "    text, skills = generate_resume(role)\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 8, line)\n",
    "    file_path = f\"test_resumes/resume_{i+1}.pdf\"\n",
    "    pdf.output(file_path)\n",
    "    pdf_paths.append(file_path)\n",
    "    ground_truth_skills.append(set(map(str.lower, skills)))\n",
    "\n",
    "print(f\"✅ Generated {NUM_RESUMES} synthetic resumes in 'test_resumes/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9be84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_skills = []\n",
    "ats_scores = []\n",
    "for path in pdf_paths:\n",
    "    txt = extract_text_from_pdf(path)\n",
    "    predicted_skills.append(extract_skills_from_text(txt))\n",
    "    ats_scores.append(calculate_ats_score(txt))\n",
    "\n",
    "# ---- Skill Metrics ----\n",
    "p = sum(len(gt & pred)/(len(pred) if pred else 1) for gt,pred in zip(ground_truth_skills, predicted_skills))/NUM_RESUMES\n",
    "r = sum(len(gt & pred)/(len(gt) if gt else 1) for gt,pred in zip(ground_truth_skills, predicted_skills))/NUM_RESUMES\n",
    "f1 = sum((2*len(gt & pred)/(len(gt)+len(pred)) if gt or pred else 0) for gt,pred in zip(ground_truth_skills, predicted_skills))/NUM_RESUMES\n",
    "\n",
    "print(f\"Skill Extraction Precision: {p:.2f}\")\n",
    "print(f\"Skill Extraction Recall:    {r:.2f}\")\n",
    "print(f\"Skill Extraction F1:        {f1:.2f}\")\n",
    "\n",
    "# ---- ATS vs Recruiter Correlation ----\n",
    "recruiter_scores = [random.randint(50,95) for _ in range(NUM_RESUMES)]\n",
    "corr, _ = pearsonr(recruiter_scores, ats_scores)\n",
    "print(f\"Pearson correlation (ATS vs Recruiter): {corr:.2f}\")\n",
    "\n",
    "plt.scatter(recruiter_scores, ats_scores)\n",
    "plt.xlabel(\"Recruiter Scores\")\n",
    "plt.ylabel(\"ATS Scores\")\n",
    "plt.title(\"ATS vs Recruiter\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- JD Ranking Real Test ----\n",
    "jd_text = \"We are looking for a Python developer with Flask, SQL, and Docker experience.\"\n",
    "ranking = rank_resumes(jd_text, pdf_paths)\n",
    "print(\"\\nTop 5 Ranked Resumes:\")\n",
    "for row in ranking[:5]:\n",
    "    print(row)\n",
    "\n",
    "# Compare with random recruiter ranking (replace with real if available)\n",
    "model_ranks = [r['filename'] for r in ranking]\n",
    "recruiter_ranks = model_ranks.copy()\n",
    "random.shuffle(recruiter_ranks)\n",
    "\n",
    "# Spearman correlation\n",
    "rho, _ = spearmanr(range(len(recruiter_ranks)), [model_ranks.index(r)+1 for r in recruiter_ranks])\n",
    "print(f\"Spearman Rank Correlation: {rho:.2f}\")\n",
    "\n",
    "# Top-3 accuracy\n",
    "top3_model = set(model_ranks[:3])\n",
    "top3_recruiter = set(recruiter_ranks[:3])\n",
    "top3_acc = len(top3_model & top3_recruiter)/3\n",
    "print(f\"Top-3 accuracy JD ranking: {top3_acc*100:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
